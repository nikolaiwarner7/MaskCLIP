{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config CONFIG] [--load-from LOAD_FROM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1060e9a4-537a-4d54-b6bf-864f51825a5b\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/root/.local/share/jupyter/runtime/kernel-v2-411559qpytvDZCR9pY.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/root/MaskCLIP')\n",
    "import sys\n",
    "sys.path.append('/root/MaskCLIP/')\n",
    "sys.path.append('/root/MaskCLIP/mmseg')\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "from mmseg.apis import single_gpu_test\n",
    "import argparse\n",
    "from mmcv.utils import Config, DictAction, get_git_hash\n",
    "from mmcv.cnn.utils import revert_sync_batchnorm\n",
    "import mmcv\n",
    "#from mmseg.utils import get_device\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train a segmentor')\n",
    "\n",
    "parser.add_argument('--config', default='configs/maskclip_plus/zero_shot/maskclip_plus_r50_deeplabv2_r101-d8_512x512_20k_voc12aug_20.py',\\\n",
    "     help='test config file path')\n",
    "parser.add_argument(\n",
    "    '--load-from', default='test_outs/latest.pth', help='the checkpoint file to load weights from')\n",
    "args = parser.parse_args()\n",
    "cfg = Config.fromfile(args.config)\n",
    "\n",
    "# Changes to switch to our RGB-S data\n",
    "cfg.data.train.img_dir = 'RGB_S_Images/train'\n",
    "cfg.data.train.ann_dir = 'RGB_S_Annotations/train'\n",
    "cfg.data.train.split = 'ImageSets/Segmentation/RGBS_train.txt'\n",
    "cfg.data.train.type = 'PascalVOCDatasetRGBS'\n",
    "\n",
    "# Normalization in 4D\n",
    "# Set mean to 0.5, std 0.5 (0,1) range of data for saliency\n",
    "#\n",
    "cfg.data.train['pipeline'][6] = \\\n",
    "    {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53, 0.5], 'std': [58.395, 57.12, 57.375, 0.5], 'to_rgb': True}\n",
    "\n",
    "# Remove unnecessary augmentations (changes shape) for now\n",
    "cfg.data.train['pipeline'].pop(5) # PhotoMetricDistortion\n",
    "\n",
    "# Set parameters for validation data\n",
    "cfg.data.val.img_dir = 'RGB_S_Images/val'\n",
    "cfg.data.val.ann_dir = 'RGB_S_Annotations/val'\n",
    "cfg.data.val.split = 'ImageSets/Segmentation/RGBS_val.txt'\n",
    "cfg.data.val.type = 'PascalVOCDatasetRGBS'\n",
    "\n",
    "# Set normalization in 4D for val\n",
    "cfg.data.val['pipeline'][1]['transforms'][2] = \\\n",
    "    {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53, 0.5], 'std': [58.395, 57.12, 57.375, 0.5], 'to_rgb': True}\n",
    "\n",
    "# Set batch size to 2 to allow batch norm in ASPP decoder head to work\n",
    "cfg.data['samples_per_gpu'] = 12\n",
    "\n",
    "## Remove reduce zero label for our binary mask, class agnostic training  \n",
    "# Otherwise produces bug with 0/255 rolled back labels\n",
    "cfg.data.train['pipeline'][1]['reduce_zero_label'] = False\n",
    "# Find where to do so for val too\n",
    "\n",
    "# Remove some augmentations\n",
    "#cfg.data.train['pipeline'][2] = {'type': 'Resize', 'img_scale': (512, 512), 'ratio_range': (1.0, 1.0)}\n",
    "#cfg.data.train['pipeline'][3] = {'type': 'RandomCrop', 'crop_size': (512, 512), 'cat_max_ratio': 1.0}\n",
    "#cfg.data.train['pipeline'][4] = {'type': 'RandomFlip', 'prob': 0.0}\n",
    "# Change hook to tensorboard\n",
    "cfg.log_config = dict(\n",
    "interval=50,\n",
    "hooks=[\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='TensorboardLoggerHook')\n",
    "])\n",
    "\n",
    "## Add in loading annotatio[15, 16, 17, 18, 19]\n",
    "cfg.data.val['pipeline'].append({})\n",
    "cfg.data.val['pipeline'][2] = cfg.data.val['pipeline'][1]\n",
    "cfg.data.val['pipeline'][1] =\\\n",
    "    {'type': 'LoadAnnotations', 'reduce_zero_label': False, 'suppress_labels': []}\n",
    "\n",
    "## Make sure it collects gt semantic seg\n",
    "cfg.data.val['pipeline'][2]['transforms'][3]['keys'].append('gt_semantic_seg')\n",
    "cfg.data.val['pipeline'][2]['transforms'][4]['keys'].append('gt_semantic_seg')\n",
    "\n",
    "# Remove some augmentationsfrom val pipeline\n",
    "#cfg.data.val['pipeline'][2]['transforms'][1] = {'type': 'RandomFlip', 'prob': 0.0}\n",
    "#cfg.data.val['pipeline'][2]['transforms'][2] = {'type': 'Resize', 'img_scale': (512, 512), 'ratio_range': (1.0, 1.0)}\n",
    "\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "# More changes to switch to RGB-S data\n",
    "datasets[0].img_suffix = '.npy'\n",
    "datasets[0].seg_map_suffix = '.npy'\n",
    "\n",
    "# Set the number of training steps (iterations)\n",
    "cfg.runner['max_iters'] = 3e5\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "\n",
    "# SyncBN is not support for DP\n",
    "model = revert_sync_batchnorm(model)\n",
    "\n",
    "# Create work_dir\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.seed = 5050\n",
    "#cfg.device = get_device()\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskclip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d7c13ee1d976b847d73e696bf4bcec172d4cf91721bd48661cfbf0119c2de9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
